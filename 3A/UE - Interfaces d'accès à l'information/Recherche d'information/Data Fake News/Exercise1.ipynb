{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eVrcHNZpQLUz"
   },
   "source": [
    "# Exercices\n",
    " \n",
    "- Les \"fake news\" sont des informations erronées ou des désinformations diffusées dans le pays par le bouche-à-oreille et, plus récemment, par les communications numériques tels que les messages de l'application \"What's app\", les messages des médias sociaux, etc.\n",
    "\n",
    "- Les fake News se propagent plus rapidement que les vraies News et créent des problèmes et des craintes au sein des groupes et de la société.\n",
    "\n",
    "- Nous allons nous attaquer à ces problèmes en utilisant des techniques NLP, l'objectif est de prédire (classer)  si un message/texte donné est **un vrai ou un faux message**.\n",
    " \n",
    "L'objectif est de comparer différentes approches de représentation de textes :\n",
    "- codage de textes simple tf.idf, simple comptage\n",
    "- codage wordembeddings\n",
    "- codage par des transformers\n",
    "\n",
    "et différentes approches de de classification \n",
    "- méthode classique (tRegression logistoc, un KNN, ...), bibliothèques : pytorch ou SKLEARN\n",
    "- méthode basée sur les tranfomers\n",
    "- - utilisation d'un pipeline (tout prêt)\n",
    "  - utitisation d'un modèle avec votre propre finetuning\n",
    "\n",
    "sur deux dataset différents un en francais le second en anglais.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wU5KDovsV9ez",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **Le dataset FakeNews**\n",
    "- Ces données se composent de trois colonnes : Titre, Texte,  Label\n",
    "- Le texte est une déclaration ou un message concernant un événement ou une situation particulière.\n",
    "- La caractéristique label indique si le texte donné est faux ou réel.\n",
    "- Comme il n'y a que deux classes (Fake ou Réel) , ce problème relève de la classification binaire.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 1 : Classification classique avec différentes représentations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset en anglais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Three more states refuse Trump commission's vo...</td>\n",
       "      <td>WASHINGTON (Reuters) - Maryland, Delaware and ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trump Crosses The Line, Attacks Civil Rights ...</td>\n",
       "      <td>Georgia Congressman John Lewis is one of Ameri...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IS TRUMP A RACIST? Famous Italian-American “Ge...</td>\n",
       "      <td>Robert Davi gives a great answer to Neil Cavut...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ted Cruz Gets His Unethical A** Handed To Him...</td>\n",
       "      <td>Seth Meyers destroyed Republican presidential ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Putin says Trump hampered from delivering elec...</td>\n",
       "      <td>SOCHI, Russia (Reuters) - Russian President Vl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Three more states refuse Trump commission's vo...   \n",
       "1   Trump Crosses The Line, Attacks Civil Rights ...   \n",
       "2  IS TRUMP A RACIST? Famous Italian-American “Ge...   \n",
       "3   Ted Cruz Gets His Unethical A** Handed To Him...   \n",
       "4  Putin says Trump hampered from delivering elec...   \n",
       "\n",
       "                                                text  label  \n",
       "0  WASHINGTON (Reuters) - Maryland, Delaware and ...      1  \n",
       "1  Georgia Congressman John Lewis is one of Ameri...      0  \n",
       "2  Robert Davi gives a great answer to Neil Cavut...      0  \n",
       "3  Seth Meyers destroyed Republican presidential ...      0  \n",
       "4  SOCHI, Russia (Reuters) - Russian President Vl...      1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import pandas library\n",
    "import pandas as pd\n",
    "\n",
    "#read the dataset with name \"data_fake_news\" and store it in a variable df\n",
    "df = pd.read_csv(\"data/fake_news_en.csv\")\n",
    "\n",
    "#print top 5 rows\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "joLuZmFpT-fY",
    "outputId": "77d48614-f6b3-4227-e90e-dc8ddb17381b"
   },
   "outputs": [],
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemple de split des données, mais vous pourrez utiliser n'importe quel moyen (bibliothèque)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "NjJqi7UBT-nr"
   },
   "outputs": [],
   "source": [
    "#import train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.text, \n",
    "    df.label, \n",
    "    test_size=0.2, # 20% samples will go to test dataset\n",
    "    random_state=42,\n",
    "    stratify=df.label\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5lAD0iqGcdCn",
    "outputId": "4efb3c3c-0ad4-4501-d815-35a902095848"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35918,) (8980,)\n"
     ]
    }
   ],
   "source": [
    "# print the shapes of X_train and X_test\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 1** :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u6h8ZZLxZd79"
   },
   "source": [
    "- Utiliser une représentation simple (CountVectorizer avec unigrams). (on supprime les mots vides, ...)\n",
    "- Utiliser un classifier de votre choix (par exemple **RandomForest**.\n",
    "- Afficher le rapport de classification \n",
    "\n",
    "\n",
    "**A TITRE INFICATIF voici le schéma que vous pourrez suivre**</br>\n",
    "Attention, l'exemple ci-dessous se base sur la biliothèque sklearn (ce n'est qu'un exemple);, vous pourrez utiliser n'importe quelle biliothèque."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vGg2iXv6g40l",
    "outputId": "3f895ca5-7606-4220-b9a2-7c26d9160a9b"
   },
   "outputs": [],
   "source": [
    "#import CountVectorizer, RandomForest, , classification_report from sklearn \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "#0 Choisir un classifieur le modèle\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "#1. Transform (encode) text to countvectors \n",
    "cv = CountVectorizer(\n",
    "    ngram_range=(1, 1),\n",
    "    stop_words='english',\n",
    "    max_features=5000,\n",
    "    min_df=2,\n",
    "    strip_accents='unicode',\n",
    "    lowercase=True\n",
    ")\n",
    "\n",
    "#2. fit_transform (trasnform) with X_train (X_test)\n",
    "X_train_cv = cv.fit_transform(X_train)\n",
    "X_test_cv = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4696\n",
      "           1       1.00      1.00      1.00      4284\n",
      "\n",
      "    accuracy                           1.00      8980\n",
      "   macro avg       1.00      1.00      1.00      8980\n",
      "weighted avg       1.00      1.00      1.00      8980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#3. get the predictions for X_test and store it in y_pred\n",
    "clf.fit(X_train_cv, y_train)\n",
    "y_pred = clf.predict(X_test_cv)\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 2** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I08-kc_JYCNL"
   },
   "source": [
    "- Utiliser une représentation combinant unigrams et bi-grammes `CountVectorizer`\n",
    "- Utiliser un classifier de votre choix \n",
    "- Afficher le rapport de classification \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8zetSmBrXmjM",
    "outputId": "b372f53c-8cbc-496f-ef4d-9fecff044230"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4696\n",
      "           1       1.00      1.00      1.00      4284\n",
      "\n",
      "    accuracy                           1.00      8980\n",
      "   macro avg       1.00      1.00      1.00      8980\n",
      "weighted avg       1.00      1.00      1.00      8980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# définir le modèle\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "#1. create a  Transform text to countvectors \n",
    "\n",
    "cv_bigram = CountVectorizer(\n",
    "    ngram_range=(1, 2),\n",
    "    stop_words='english',\n",
    "    max_features=5000,\n",
    "    min_df=2,\n",
    "    strip_accents='unicode',\n",
    "    lowercase=True\n",
    ")\n",
    "\n",
    "#2. fit_ transform X_train (utiliser fit_transform de sklearn)\n",
    "\n",
    "X_train_cv_bigram = cv_bigram.fit_transform(X_train)\n",
    "X_test_cv_bigram = cv_bigram.transform(X_test)\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "\n",
    "clf.fit(X_train_cv_bigram, y_train)\n",
    "y_pred = clf.predict(X_test_cv_bigram)\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 3** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hmrXmL_3Z2y6"
   },
   "source": [
    "- Utiliser **TF-IDF vectorizer**  avec unigrams.\n",
    "- Utiliser un classifier de votre choix \n",
    "- Afficher le rapport de classification \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "djsDsThaaCSO",
    "outputId": "b4514ab2-f6ad-45e1-b91b-e88393e975e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      4696\n",
      "           1       0.98      0.99      0.99      4284\n",
      "\n",
      "    accuracy                           0.99      8980\n",
      "   macro avg       0.99      0.99      0.99      8980\n",
      "weighted avg       0.99      0.99      0.99      8980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "# définir le modèle (utiliser LogisticRegression)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "\n",
    "#1. Vectorise the Text \n",
    "tfidf = TfidfVectorizer(\n",
    "    ngram_range=(1, 1),\n",
    "    stop_words='english',\n",
    "    max_features=5000,\n",
    "    min_df=2,\n",
    "    strip_accents='unicode',\n",
    "    lowercase=True\n",
    ")\n",
    "\n",
    "#2. fit (transform) with X_train ....\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "y_pred = clf.predict(X_test_tfidf)\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 4** :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U9GZPaQbbJbx"
   },
   "source": [
    "- Représentation d'un texte avec des embeddings (word2vec ou BERT, ...).\n",
    "- Utiliser un classifier de votre choix (par exemple **RandomForest**.)\n",
    "- Afficher le rapport de classification \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f2y1Cy4Bauxu",
    "outputId": "ac6bf255-a218-400c-c4a9-790f4a89dfb1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\offic\\AppData\\Roaming\\Python\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\offic\\AppData\\Roaming\\Python\\Python312\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\offic\\.cache\\huggingface\\hub\\models--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# définir le modèle\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "#1. Transform text to tfidfvectorizer \n",
    "\n",
    "def get_bert_embeddings(texts, tokenizer, model):\n",
    "    # Initialiser la liste pour stocker les embeddings\n",
    "    embeddings = []\n",
    "    \n",
    "    # Passer en mode évaluation\n",
    "    model.eval()\n",
    "    \n",
    "    # Traitement par lots pour économiser la mémoire\n",
    "    batch_size = 32\n",
    "    \n",
    "    with torch.no_grad():  # Désactiver le calcul des gradients\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            # Prendre un lot de textes\n",
    "            batch_texts = texts[i:i + batch_size].tolist()\n",
    "            \n",
    "            # Tokenizer les textes\n",
    "            encoded = tokenizer(batch_texts,\n",
    "                              padding=True,\n",
    "                              truncation=True,\n",
    "                              max_length=512,\n",
    "                              return_tensors='pt')\n",
    "            \n",
    "            # Obtenir les embeddings\n",
    "            outputs = model(**encoded)\n",
    "            \n",
    "            # Prendre l'embedding du token [CLS] (première position)\n",
    "            batch_embeddings = outputs.last_hidden_state[:, 0, :].numpy()\n",
    "            embeddings.extend(batch_embeddings)\n",
    "    \n",
    "    return np.array(embeddings)\n",
    "\n",
    "# Charger le modèle BERT et le tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = AutoModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Transformer les textes en embeddings\n",
    "X_train_embeddings = get_bert_embeddings(X_train, tokenizer, model)\n",
    "X_test_embeddings = get_bert_embeddings(X_test, tokenizer, model)\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "clf.fit(X_train_embeddings, y_train)\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = clf.predict(X_test_embeddings)\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Refaire le travail sur le Dataset en francais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "tf_idf_exercise.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
